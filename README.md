# ðŸ§  Deep Learning on CIFAR-10 and MNIST


---

## ðŸ“˜ Project Overview

This project explores the use of various deep learning architectures â€” **AlexNet**, **VGGNet**, and **ResNet** â€” to classify images from the **CIFAR-10** and **MNIST** datasets. The goal is to evaluate and compare the performance of these models on image classification tasks.

---

## ðŸ—‚ï¸ Datasets Used

- **MNIST**: Handwritten digits (28x28 grayscale images, 10 classes)
- **CIFAR-10**: Color images (32x32 RGB images, 10 classes)

---

## ðŸ§  Neural Networks Implemented

- **AlexNet**
- **VGGNet** 
- **ResNet** 

These models were implemented using **PyTorch** and **TensorFlow** frameworks.

---

## ðŸ”§ Methodology

1. **Data Preprocessing**
   - Normalization
   - One-hot encoding of labels
   - Data augmentation for CIFAR-10

2. **Model Training**
   - Transfer learning or training from scratch
   - Optimizers used: Adam, SGD
   - Loss function: CrossEntropyLoss

3. **Evaluation**
   - Accuracy and loss tracking
   - Confusion matrix
   - Training/validation plots

---

## ðŸ“Š Results

| Model     | MNIST Accuracy | CIFAR-10 Accuracy |
|-----------|----------------|-------------------|
| AlexNet   | ~98%           | ~85%              |
| VGGNet    | ~98.5%         | ~88%              |
| ResNet    | ~99%           | ~90%              |

> âš ï¸ *Actual results may vary depending on training settings and compute resources.*

---

## ðŸ“ Requirements

- `numpy`
- `matplotlib`
- `torch` / `tensorflow`
- `torchvision`
- `scikit-learn`

Install using pip:

```bash
pip install numpy matplotlib torch torchvision scikit-learn tensorflow
```

---

## ðŸš€ How to Run

```bash
# Train a specific model on MNIST or CIFAR-10
python train.py --model resnet --dataset cifar10
```

> Use flags like `--epochs`, `--batch-size`, or `--lr` to customize training.

---

## ðŸ“„ Output

- Accuracy and loss plots
- Confusion matrices
- Trained model weights

---

## ðŸ“¬ Contact

For queries, contact: **Manish Raut** â€“ M.Tech (Data Science)

